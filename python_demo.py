#!/usr/bin/env python3
"""
Exemple d'utilisation des bindings Python de Doc Loader (extracteur-docs-rs)

Ce script dÃ©montre comment utiliser la bibliothÃ¨que Python pour traiter
diffÃ©rents types de documents et extraire des donnÃ©es structurÃ©es.

Installation: pip install extracteur-docs-rs
"""

import sys
import os
import json
from pathlib import Path

# Tentative d'import du module
try:
    import doc_loader
    print("âœ… Module doc_loader (extracteur-docs-rs) importÃ© avec succÃ¨s")
except ImportError as e:
    print("âŒ Erreur d'import du module doc_loader:")
    print(f"   {e}")
    print("\nğŸ’¡ Pour rÃ©soudre ce problÃ¨me:")
    print("   Option 1 (recommandÃ©e): pip install extracteur-docs-rs")
    print("   Option 2 (depuis les sources):")
    print("     1. Installez maturin: pip install maturin")
    print("     2. Compilez les bindings: maturin develop --features python")
    print("   3. Relancez ce script")
    sys.exit(1)


def demo_basic_usage():
    """DÃ©monstration de l'usage de base"""
    print("\nğŸ”§ === DÃ©monstration Usage de Base ===")
    
    # CrÃ©er un processeur
    processor = doc_loader.PyUniversalProcessor()
    print("âœ… Processeur crÃ©Ã©")
    
    # Formats supportÃ©s
    extensions = processor.get_supported_extensions()
    print(f"ğŸ“‹ Formats supportÃ©s: {', '.join(extensions)}")
    
    # Test avec fichier d'exemple
    sample_file = "samples/test_sample.txt"
    if os.path.exists(sample_file):
        print(f"\nğŸ“„ Traitement du fichier: {sample_file}")
        
        # Traitement simple
        result = processor.process_file(sample_file)
        
        print(f"âœ… Traitement terminÃ©:")
        print(f"   ğŸ“Š Chunks gÃ©nÃ©rÃ©s: {result.chunk_count()}")
        print(f"   ğŸ“ Mots totaux: {result.total_word_count()}")
        print(f"   ğŸ”¤ CaractÃ¨res totaux: {result.total_char_count()}")
        
        # Affichage des mÃ©tadonnÃ©es
        metadata = result.document_metadata
        print(f"\nğŸ“‹ MÃ©tadonnÃ©es:")
        print(f"   Nom: {metadata.filename}")
        print(f"   Type: {metadata.document_type}")
        print(f"   Taille: {metadata.file_size} bytes")
        
        # Affichage du premier chunk
        if result.chunks:
            first_chunk = result.chunks[0]
            print(f"\nğŸ“„ Premier chunk:")
            print(f"   ID: {first_chunk.id}")
            print(f"   Index: {first_chunk.chunk_index}")
            print(f"   Mots: {first_chunk.word_count}")
            print(f"   Contenu (50 premiers chars): {first_chunk.content[:50]}...")
    else:
        print(f"âš ï¸  Fichier d'exemple non trouvÃ©: {sample_file}")


def demo_custom_parameters():
    """DÃ©monstration avec paramÃ¨tres personnalisÃ©s"""
    print("\nâš™ï¸  === DÃ©monstration ParamÃ¨tres PersonnalisÃ©s ===")
    
    # ParamÃ¨tres personnalisÃ©s
    params = doc_loader.PyProcessingParams(
        chunk_size=400,
        overlap=50,
        clean_text=True,
        extract_metadata=True,
        preserve_formatting=False
    )
    
    print(f"âš™ï¸  ParamÃ¨tres configurÃ©s:")
    print(f"   Taille chunk: {params.chunk_size}")
    print(f"   Chevauchement: {params.overlap}")
    print(f"   Nettoyage texte: {params.clean_text}")
    
    # Test avec fichier d'exemple
    sample_file = "samples/test_sample.txt"
    if os.path.exists(sample_file):
        processor = doc_loader.PyUniversalProcessor()
        result = processor.process_file(sample_file, params)
        
        print(f"\nâœ… RÃ©sultat avec paramÃ¨tres personnalisÃ©s:")
        print(f"   ğŸ“Š Chunks: {result.chunk_count()}")
        print(f"   ğŸ“ Mots: {result.total_word_count()}")
        
        # Analyse des tailles de chunks
        chunk_sizes = [len(chunk.content) for chunk in result.chunks]
        if chunk_sizes:
            print(f"   ğŸ“ Taille chunk moyenne: {sum(chunk_sizes) / len(chunk_sizes):.0f} chars")
            print(f"   ğŸ“ Taille min/max: {min(chunk_sizes)}/{max(chunk_sizes)} chars")


def demo_convenience_functions():
    """DÃ©monstration des fonctions de commoditÃ©"""
    print("\nğŸ› ï¸  === DÃ©monstration Fonctions de CommoditÃ© ===")
    
    # Extensions supportÃ©es
    extensions = doc_loader.supported_extensions()
    print(f"ğŸ“‹ Extensions: {extensions}")
    
    # Traitement direct avec fonction de commoditÃ©
    sample_file = "samples/test_sample.txt"
    if os.path.exists(sample_file):
        print(f"\nğŸ“„ Traitement avec fonction de commoditÃ©:")
        result = doc_loader.process_file(sample_file, chunk_size=300)
        print(f"   âœ… {result.chunk_count()} chunks gÃ©nÃ©rÃ©s")
    
    # Traitement de texte direct
    sample_text = "Ceci est un exemple de texte Ã  traiter. " * 10
    print(f"\nğŸ“ Traitement de texte direct:")
    result = doc_loader.process_text(sample_text, chunk_size=100)
    print(f"   âœ… {result.chunk_count()} chunks gÃ©nÃ©rÃ©s")
    print(f"   ğŸ“ Texte original: {len(sample_text)} chars")
    print(f"   ğŸ“ Premier chunk: {result.chunks[0].content[:50]}...")


def demo_json_export():
    """DÃ©monstration de l'export JSON"""
    print("\nğŸ’¾ === DÃ©monstration Export JSON ===")
    
    sample_file = "samples/test_sample.txt"
    if os.path.exists(sample_file):
        result = doc_loader.process_file(sample_file, chunk_size=200)
        
        # Export JSON
        json_output = result.to_json()
        
        # Sauvegarde
        output_file = "output_example.json"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(json_output)
        
        print(f"âœ… JSON exportÃ© vers: {output_file}")
        print(f"   ğŸ“Š Taille du fichier: {len(json_output)} chars")
        
        # Affichage d'un extrait
        try:
            json_data = json.loads(json_output)
            print(f"   ğŸ“‹ Structure JSON:")
            print(f"      - document_metadata: {len(json_data.get('document_metadata', {}))} clÃ©s")
            print(f"      - chunks: {len(json_data.get('chunks', []))} Ã©lÃ©ments")
            print(f"      - total_chunks: {json_data.get('total_chunks', 'N/A')}")
        except json.JSONDecodeError:
            print("   âš ï¸  Erreur de parsing JSON")


def demo_batch_processing():
    """DÃ©monstration du traitement par lot"""
    print("\nğŸ”„ === DÃ©monstration Traitement par Lot ===")
    
    samples_dir = "samples"
    if os.path.exists(samples_dir):
        processor = doc_loader.PyUniversalProcessor()
        supported_exts = processor.get_supported_extensions()
        
        files_processed = 0
        total_chunks = 0
        total_words = 0
        
        print(f"ğŸ“ Traitement du rÃ©pertoire: {samples_dir}")
        
        for filename in os.listdir(samples_dir):
            filepath = os.path.join(samples_dir, filename)
            if os.path.isfile(filepath):
                # VÃ©rifier l'extension
                ext = os.path.splitext(filename)[1].lower().lstrip('.')
                if ext in supported_exts:
                    try:
                        print(f"   ğŸ“„ Traitement: {filename}")
                        result = processor.process_file(filepath)
                        
                        files_processed += 1
                        total_chunks += result.chunk_count()
                        total_words += result.total_word_count()
                        
                        print(f"      âœ… {result.chunk_count()} chunks, {result.total_word_count()} mots")
                        
                    except Exception as e:
                        print(f"      âŒ Erreur: {e}")
                else:
                    print(f"   â­ï¸  IgnorÃ© (format non supportÃ©): {filename}")
        
        print(f"\nğŸ“Š RÃ©sumÃ© du traitement par lot:")
        print(f"   ğŸ“ Fichiers traitÃ©s: {files_processed}")
        print(f"   ğŸ§© Chunks totaux: {total_chunks}")
        print(f"   ğŸ“ Mots totaux: {total_words}")
    else:
        print(f"âš ï¸  RÃ©pertoire samples non trouvÃ©: {samples_dir}")


def demo_error_handling():
    """DÃ©monstration de la gestion d'erreurs"""
    print("\nâš ï¸  === DÃ©monstration Gestion d'Erreurs ===")
    
    processor = doc_loader.PyUniversalProcessor()
    
    # Test avec fichier inexistant
    print("ğŸ§ª Test avec fichier inexistant:")
    try:
        result = processor.process_file("fichier_inexistant.txt")
        print("   âŒ Erreur: devrait lever une exception")
    except Exception as e:
        print(f"   âœ… Exception attendue: {type(e).__name__}: {e}")
    
    # Test avec format non supportÃ©
    print("\nğŸ§ª Test avec fichier non supportÃ©:")
    # CrÃ©er un fichier temporaire avec extension non supportÃ©e
    temp_file = "temp_file.xyz"
    try:
        with open(temp_file, "w") as f:
            f.write("Test content")
        
        result = processor.process_file(temp_file)
        print("   âŒ Erreur: devrait lever une exception")
    except Exception as e:
        print(f"   âœ… Exception attendue: {type(e).__name__}: {e}")
    finally:
        if os.path.exists(temp_file):
            os.remove(temp_file)


def main():
    """Fonction principale"""
    print("ğŸ === DÃ©monstration des Bindings Python Doc Loader ===")
    print(f"ğŸ“ RÃ©pertoire de travail: {os.getcwd()}")
    
    # ExÃ©cution des dÃ©monstrations
    demo_basic_usage()
    demo_custom_parameters()
    demo_convenience_functions()
    demo_json_export()
    demo_batch_processing()
    demo_error_handling()
    
    print("\nğŸ‰ === DÃ©monstration TerminÃ©e ===")
    print("\nğŸ’¡ Pour plus d'informations:")
    print("   ğŸ“– Consultez docs/python_usage.md")
    print("   ğŸ”§ Consultez docs/api.md")
    print("   ğŸ“‹ Consultez docs/examples.md")


if __name__ == "__main__":
    main()
